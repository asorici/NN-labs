{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1F7uynq7XXN2"
   },
   "source": [
    "Generative Adversarial Networks\n",
    "===========================\n",
    "\n",
    "#### Credits to Tudor Berariu for tutorial on GAN visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "862IkSj8wfHi"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxWJFhBY12-r"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import time\n",
    "import base64\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZJ-thHO3jJh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import distributions, optim, nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-OsIBTIEUfn"
   },
   "source": [
    "## The target distribution: A Mixture of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqhyONVOEZtk"
   },
   "outputs": [],
   "source": [
    "def to_tensor(x, dtype=torch.float, device=\"cpu\"):\n",
    "    if torch.is_tensor(x):\n",
    "        return x.float().to(device)\n",
    "    return torch.tensor(x, dtype=dtype, device=device)\n",
    "\n",
    "\n",
    "class GaussianMixture:\n",
    "    \"\"\" Mixture of Gaussians. It uses Normal or MultivariateNormal depending\n",
    "        on the tensor you feed for the covariance.\n",
    "        \n",
    "        If the covariances have shape ncomponents x nvars, then it assumes\n",
    "        covariances are diagonal and the variables are independent.\n",
    "        If the covariances are ncomponets x nvars x nvars, a MultivariateNormal\n",
    "        is used instead.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, means, covariances, weights=None, device=\"cpu\"):\n",
    "        means = to_tensor(means, device=device)\n",
    "        covariances = to_tensor(covariances, device=device)\n",
    "        \n",
    "        if weights is None:\n",
    "            weights = torch.ones(len(means), device=device)\n",
    "        weights = to_tensor(weights, device=device)\n",
    "        weights.div_(weights.sum())\n",
    "        \n",
    "        self.__ncomponents = ncomponents = len(means)\n",
    "        assert ncomponents == len(weights) == len(covariances)\n",
    "        \n",
    "        if means.ndimension() < 2:\n",
    "            means.unsqueeze_(1)\n",
    "        if covariances.ndimension() < 2:\n",
    "            covariances.unsqueeze_(1)\n",
    "        \n",
    "        self.__nvars = nvars = means.shape[1]\n",
    "        assert covariances.shape[1] == nvars == covariances.shape[-1]\n",
    "        \n",
    "        self.__weights = weights\n",
    "        self.__full_covariance = covariances.ndimension() == 3\n",
    "        if self.__full_covariance:\n",
    "            self.__dist = distributions.MultivariateNormal(means, covariances)\n",
    "        else:\n",
    "            self.__dist = distributions.Normal(means, covariances.sqrt())\n",
    "        self.__mixture_dist = distributions.Categorical(weights)\n",
    "        \n",
    "        self.device = device\n",
    "    \n",
    "    @property\n",
    "    def ncomponents(self):\n",
    "        return self.__ncomponents\n",
    "    \n",
    "    @property\n",
    "    def nvars(self):\n",
    "        return self.__nvars\n",
    "    \n",
    "    def sample(self,nsamples):\n",
    "        \"\"\" Here we sample from the mixture.\n",
    "        \"\"\"\n",
    "        idxs = self.__mixture_dist.sample((nsamples, 1, 1))\n",
    "        return torch.gather(\n",
    "            self.__dist.sample((nsamples,)),  # nsamples x ncomponents x nvars\n",
    "            1,\n",
    "            idxs.expand(nsamples, 1, self.nvars) # nsamples x 1 x nvars\n",
    "        ).squeeze(1)\n",
    "    \n",
    "    def log_prob(self, xs):\n",
    "        \"\"\" Here we compute the log-probability of examples in xs under the\n",
    "            mixture of gaussians.\n",
    "        \"\"\"\n",
    "        if xs.ndimension() == 1 and self.nvars == 1:\n",
    "            xs = xs.unsqueeze(1)\n",
    "        assert xs.shape[1] == self.__nvars\n",
    "        \n",
    "        xs = xs.unsqueeze(1).expand(-1, self.__ncomponents, -1)\n",
    "        xs = xs.to(device)\n",
    "        log_probs = self.__dist.log_prob(xs)\n",
    "        if not self.__full_covariance:\n",
    "            assert log_probs.shape == (len(xs), self.ncomponents, self.nvars)\n",
    "            log_probs = log_probs.sum(dim=2)\n",
    "        return torch.log(log_probs.exp() @ self.__weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3j2laU-ElYe"
   },
   "source": [
    "## The Generative Adversarial Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2LH19xeOErWY"
   },
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    \"\"\" The standard GAN.\n",
    "        Both the encoder and the decoder habe two hidden layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, z_sz, h_sz, x_sz=1):\n",
    "        self.__x_sz = x_sz = int(x_sz)\n",
    "        self.__z_sz = z_sz = int(z_sz)\n",
    "        self.__device = torch.device(\"cpu\")\n",
    "        \n",
    "        self.generator = nn.Sequential(\n",
    "            nn.Linear(z_sz, h_sz), nn.LeakyReLU(),\n",
    "            # nn.Linear(h_sz, h_sz), nn.LeakyReLU(),\n",
    "            nn.Linear(h_sz, x_sz)\n",
    "        )\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(x_sz, h_sz), nn.LeakyReLU(),\n",
    "            # nn.Linear(h_sz, h_sz), nn.LeakyReLU(),\n",
    "            nn.Linear(h_sz, 1)\n",
    "        )\n",
    "        \n",
    "    @property\n",
    "    def z_sz(self):\n",
    "        return self.__z_sz\n",
    "        \n",
    "    @property\n",
    "    def device(self):\n",
    "        return self.__device\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.generator.to(device)\n",
    "        self.discriminator.to(device)\n",
    "        self.__device = device\n",
    "        \n",
    "\n",
    "    def sample(self, nsamples):\n",
    "        \"\"\" Here we produce samples using our generator.\n",
    "        \"\"\"\n",
    "        zs = torch.randn(nsamples, self.z_sz, device=self.__device)\n",
    "        return self.generator(zs)\n",
    "    \n",
    "    def discriminate(self, data):\n",
    "        \"\"\" Here we ask the discriminator whether the data it sees is real or\n",
    "            fake.\n",
    "        \"\"\"\n",
    "        return torch.sigmoid(self.discriminator(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Zu6YrgWj4tK"
   },
   "source": [
    "## Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlhmX4FtkO5e"
   },
   "outputs": [],
   "source": [
    "def fig2b64(figure):\n",
    "    \"\"\" Returns raw encoding of a png image rendered from the given figure.\n",
    "    \"\"\"\n",
    "    data = io.BytesIO()\n",
    "    figure.savefig(data, format='png')\n",
    "    data.seek(0)\n",
    "    return base64.b64encode(data.read()).decode()\n",
    "\n",
    "\n",
    "class Reporter:\n",
    "    \n",
    "    fig_id = 0\n",
    "    \n",
    "    def __init__(self, figsize=(16, 10), pdfs_xlim=(-1, 1), model=\"GAN\"):\n",
    "        Reporter.fig_id = self.__fig_id = fig_id = Reporter.fig_id + 1\n",
    "        self.__figure = figure = plt.figure(num=self.__fig_id, figsize=figsize)\n",
    "        \n",
    "        self.__pdfs_ax = pdfs_ax = figure.add_subplot(3, 1, 1)\n",
    "        pdfs_ax.set_xlim(pdfs_xlim)\n",
    "        pdfs_ax.set_ylim((-0.1, 1.6))\n",
    "        \n",
    "        self.__accs_ax = accs_ax = figure.add_subplot(3, 1, 2)\n",
    "        self.__loss_ax = loss_ax = figure.add_subplot(3, 1, 3, sharex=accs_ax)\n",
    "        \n",
    "        # TODO: nu se afiseaza bine\n",
    "        # figure.suptitle(f\"{model:s} learning a distribution\")\n",
    "\n",
    "        pdfs_ax.set_title(\"Probability Density Functions\")\n",
    "        pdfs_ax.set_xlim(pdfs_xlim)\n",
    "        accs_ax.set_title(\"Discriminator accuracy\")\n",
    "        loss_ax.set_title(\"Loss functions\")\n",
    "        \n",
    "        figure.tight_layout()\n",
    "        \n",
    "        raw_img = fig2b64(figure)\n",
    "\n",
    "        IPython.display.display_html(\n",
    "            f'<table>'\n",
    "            f'<tr><td>D. accuracy</td><td>:</td><td class=\"acc\"></td></tr>'\n",
    "            f'<tr><td>D. loss</td><td>:</td><td class=\"dloss\"></td></tr>'\n",
    "            f'<tr><td>G. loss</td><td>:</td><td class=\"gloss\"></td></tr>'\n",
    "            f'</table>'\n",
    "            f'<img class=\"plots\" src=\"data:image/png;base64,{raw_img}\"></img>',\n",
    "            raw=True\n",
    "        )\n",
    "        \n",
    "        self.__lines = {}\n",
    "    \n",
    "    def __first_update(self, trace, pdfs):\n",
    "        steps = trace[\"steps\"]\n",
    "        \n",
    "        # Here we plot the accuracies.\n",
    "        \n",
    "        self.__lines[\"real_acc\"], = self.__accs_ax.plot(\n",
    "            steps, trace[\"real_acc\"], label='real data',\n",
    "        )\n",
    "        self.__lines[\"fake_acc\"], = self.__accs_ax.plot(\n",
    "            steps, trace[\"fake_acc\"], label='fake data',\n",
    "        )\n",
    "        self.__lines[\"overall_acc\"], = self.__accs_ax.plot(\n",
    "            steps, trace[\"overall_acc\"], label='overall',\n",
    "        )\n",
    "        self.__accs_ax.legend()\n",
    "        \n",
    "        # Below we plot the loss functions.\n",
    "        \n",
    "        self.__lines[\"d_loss\"], = self.__loss_ax.plot(\n",
    "            steps, trace[\"d_loss\"], label='D loss',\n",
    "        )\n",
    "        self.__lines[\"g_loss\"], = self.__loss_ax.plot(\n",
    "            steps, trace[\"g_loss\"], label='G loss',\n",
    "        )\n",
    "        self.__loss_ax.legend()\n",
    "        \n",
    "        # Here we plot the pdfs, and the discriminator\n",
    "        \n",
    "        self.__lines[\"target_pdf\"], = self.__pdfs_ax.plot(\n",
    "            pdfs[\"support\"], pdfs[\"target\"], label=\"target pdf\",\n",
    "        )\n",
    "        self.__lines[\"generator_pdf\"], = self.__pdfs_ax.plot(\n",
    "            pdfs[\"support\"], pdfs[\"generator\"], label=\"generator pdf\",\n",
    "        )\n",
    "        self.__lines[\"decision\"], = self.__pdfs_ax.plot(\n",
    "            pdfs[\"support\"], pdfs[\"decision\"], label=\"discriminator\",\n",
    "            linestyle='--',\n",
    "        )\n",
    "        self.__pdfs_ax.axhline(y=0.5, alpha=0.75, linestyle=':')\n",
    "        self.__pdfs_ax.axhline(y=1, alpha=0.25, linestyle=':')\n",
    "        self.__pdfs_ax.legend()\n",
    "        \n",
    "    \n",
    "    \n",
    "    def __update_plots(self, trace, pdfs):\n",
    "        if not self.__lines:\n",
    "            self.__first_update(trace, pdfs)\n",
    "            return\n",
    "        \n",
    "        steps = trace[\"steps\"]\n",
    "        \n",
    "        self.__lines[\"real_acc\"].set_data(steps, trace[\"real_acc\"])\n",
    "        self.__lines[\"fake_acc\"].set_data(steps, trace[\"fake_acc\"])\n",
    "        self.__lines[\"overall_acc\"].set_data(steps, trace[\"overall_acc\"])\n",
    "        self.__accs_ax.relim()\n",
    "        self.__accs_ax.autoscale_view()\n",
    "        \n",
    "        self.__lines[\"d_loss\"].set_data(steps, trace[\"d_loss\"])\n",
    "        self.__lines[\"g_loss\"].set_data(steps, trace[\"g_loss\"])\n",
    "        self.__loss_ax.relim()\n",
    "        self.__loss_ax.autoscale_view()\n",
    "        \n",
    "        self.__lines[\"generator_pdf\"].set_data(pdfs[\"support\"], pdfs[\"generator\"])\n",
    "        self.__lines[\"decision\"].set_data(pdfs[\"support\"], pdfs[\"decision\"])\n",
    "\n",
    "        \n",
    "    def report(self, trace, pdfs):\n",
    "        self.__update_plots(trace, pdfs)\n",
    "        raw_img = fig2b64(self.__figure)\n",
    "        IPython.display.display_javascript(\n",
    "            f\"document.querySelector('.plots').src = 'data:image/png;base64,\"\n",
    "            f\"{raw_img}';\"\n",
    "            f\"document.querySelector('.acc').innerHTML = \"\n",
    "            f\"'{trace['overall_acc'][-1]:.3f}%';\"\n",
    "            f\"document.querySelector('.dloss').innerHTML = \"\n",
    "            f\"'{trace['d_loss'][-1]:.3f}';\"\n",
    "            f\"document.querySelector('.gloss').innerHTML = \"\n",
    "            f\"'{trace['g_loss'][-1]:.3f}';\",\n",
    "            raw=True\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def close(self):\n",
    "        plt.close(self.__fig_id)\n",
    "\n",
    "\n",
    "class GANReporter(Reporter):\n",
    "    def __init__(self, target_dist, gan, *args, **kwargs):\n",
    "        self.__gan = gan\n",
    "        self.__target_dist = target_dist\n",
    "        self.__reporting_freq = int(reporting_freq)\n",
    "        \n",
    "        self.__names = (\n",
    "            [\"real_acc\", \"fake_acc\", \"overall_acc\"] +\n",
    "            [\"d_loss\", \"g_loss\", \"d_real\", \"d_fake\"]\n",
    "        )\n",
    "        \n",
    "        self.__trace = {n: [] for n in self.__names}\n",
    "        self.__buffers = {n: [] for n in self.__names}\n",
    "        self.__pdfs = pdfs = dict({})\n",
    "            \n",
    "        target_samples = target_dist.sample(5000)\n",
    "        min_val = target_samples.min().cpu().item()\n",
    "        max_val = target_samples.max().cpu().item()\n",
    "        x_lim = 1.1 * min_val - 0.1 * max_val, 1.1 * max_val - 0.1 * min_val\n",
    "        \n",
    "        self.__support = support = torch.linspace(*x_lim, 1000)\n",
    "        pdfs[\"support\"] = support.numpy()\n",
    "        pdfs[\"target\"] = target_dist.log_prob(support).exp().cpu().numpy()\n",
    "            \n",
    "        self.__step = 0\n",
    "        self.__trace[\"steps\"] = []\n",
    "        \n",
    "        super(GANReporter, self).__init__(*args, pdfs_xlim=x_lim, **kwargs)\n",
    "            \n",
    "    def tick(self, d_loss, g_loss, real_acc, fake_acc):\n",
    "        self.__buffers[\"g_loss\"].append(g_loss)\n",
    "        self.__buffers[\"d_loss\"].append(d_loss)\n",
    "        self.__buffers[\"real_acc\"].append(real_acc)\n",
    "        self.__buffers[\"fake_acc\"].append(fake_acc)\n",
    "        self.__buffers[\"overall_acc\"].append((real_acc + fake_acc) / 2.0)\n",
    "        \n",
    "        if self.__step % self.__reporting_freq == 0:\n",
    "            for name in self.__names:\n",
    "                self.__trace[name].append(np.mean(self.__buffers[name]))\n",
    "                self.__buffers[name].clear()\n",
    "            self.__trace[\"steps\"].append(self.__step)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                support = self.__support\n",
    "                self.__pdfs[\"generator\"] = self.__approximate_generator_pdf()(\n",
    "                    support.numpy()\n",
    "                )\n",
    "                xs = support.to(gan.device).unsqueeze(1)\n",
    "                self.__pdfs[\"decision\"] = gan.discriminate(xs).cpu().numpy()\n",
    "            self.report(self.__trace, self.__pdfs)\n",
    "        self.__step += 1\n",
    "    \n",
    "    def __approximate_generator_pdf(self):\n",
    "        samples = self.__gan.sample(20000).view(-1).cpu().numpy()\n",
    "        kernel = stats.gaussian_kde(samples, bw_method=0.08)\n",
    "        return kernel\n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahIPdsV_E728"
   },
   "source": [
    "## Training the GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "FraxqHJTFeIK"
   },
   "outputs": [],
   "source": [
    "#@title Configure training\n",
    "\n",
    "nsteps = 10000 #@param {type:\"integer\"}\n",
    "batch_size = 64 #@param {type: \"integer\"}\n",
    "latent_size = 3 #@param {type: \"integer\"}\n",
    "hidden_size = 20 #@param {type: \"integer\"}\n",
    "gm_locs = [1.0, 4.0, 7.0] #@param\n",
    "gm_covars = [0.2, 0.05, 0.3] #@param\n",
    "gm_weights = [4, 1, 3] #@param\n",
    "learning_rate = 0.001 #@param {type: \"number\"}\n",
    "reporting_freq = 10 #@param {type: \"integer\"}\n",
    "discriminator_speedup = 5 #@param {type: \"integer\"}\n",
    "model = \"NS-GAN\" #@param [\"NS-GAN\", \"M-GAN\", \"W-GAN-GP\", \"W-GAN-PC\"]\n",
    "device = \"cpu\" #@param [\"cpu\", \"cuda\"]\n",
    "\n",
    "# -- Aici începe nebunia\n",
    "\n",
    "device = torch.device(device)\n",
    "gan = GAN(latent_size, hidden_size)\n",
    "gan.to(device)\n",
    "mixture = GaussianMixture(gm_locs, gm_covars, weights=gm_weights, device=device)\n",
    "\n",
    "d_optimizer = optim.Adam(gan.discriminator.parameters(), lr=learning_rate)\n",
    "g_optimizer = optim.Adam(gan.generator.parameters(), lr=learning_rate)\n",
    "\n",
    "ones = torch.ones(batch_size, 1, device=device)\n",
    "zeros = torch.zeros_like(ones)\n",
    "\n",
    "reporter = GANReporter(mixture, gan)\n",
    "\n",
    "zeros = torch.zeros_like(ones)\n",
    "\n",
    "for step in range(nsteps):\n",
    "    real_xs = mixture.sample(batch_size)\n",
    "    fake_xs = gan.sample(batch_size)\n",
    "    \n",
    "    real_logits = gan.discriminator(real_xs)\n",
    "    fake_logits = gan.discriminator(fake_xs)\n",
    "\n",
    "    # Here we optimize the discriminator\n",
    "    bce_real = F.binary_cross_entropy_with_logits(real_logits, ones)\n",
    "    bce_fake = F.binary_cross_entropy_with_logits(fake_logits, zeros)\n",
    "    d_loss = (bce_real + bce_fake) / 2.0\n",
    "\n",
    "    d_optimizer.zero_grad()\n",
    "    d_loss.backward(retain_graph=True)\n",
    "    d_optimizer.step()\n",
    "\n",
    "    # Here we optimize the generator\n",
    "\n",
    "    if step % discriminator_speedup == 0:\n",
    "\n",
    "        if model == \"NS-GAN\":\n",
    "            g_loss = F.binary_cross_entropy_with_logits(fake_logits, ones)\n",
    "        elif model == \"M-GAN\":\n",
    "            g_loss = -F.binary_cross_entropy_with_logits(fake_logits, zeros)\n",
    "\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "\n",
    "    # Here we report progress\n",
    "    real_acc = (torch.sigmoid(real_logits) >= .5).float().mean().mul(100).item()\n",
    "    fake_acc = (torch.sigmoid(fake_logits) < .5).float().mean().mul(100).item()\n",
    "    reporter.tick(d_loss.item(), g_loss.item(), real_acc, fake_acc)\n",
    "\n",
    "\n",
    "reporter.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-dDLv_O9MIj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "u-OsIBTIEUfn"
   ],
   "name": "GAN visualization.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
